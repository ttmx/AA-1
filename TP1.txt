Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

QUESTÔES:

Q1: Considerando os dados fornecidos, explique a necessidade de standardizar os valores dos atributos.
R1: Os valores são standardizados para uma propriedade não pesar mais nos classificadores do que outras devido a estar expressa numa unidade com valores absolutos de magnitudes significativamente diferentes das restantes.


Q2: Explique como calculou os parâmetros para standardização e como os usou no conjunto de teste.
R2: Para cada coluna (feature) calculámos a média e o desvio padrão da mesma, posteriormente subtraindo a cada elemento a média e dividindo esse resultado pelo desvio padrão de modo a dispor os dados segundo uma distribuição normal com média 0 e desvio padrão 1.


Q3: Explique como calculou a probabilidade a priori de um exemplo pertencer a uma classe (a probabilidade antes de ter em conta os valores dos atributos do exemplo) na sua implementação do classificador Naïve Bayes. Pode incluir um trecho relevante do código se ajudar a explicar.
R3: Utilizámos a fração do nº de elementos pertencentes a cada classe de nota sobre o nº total de notas no conjunto de treino.


Q4: Explique como o seu classificador Naïve Bayes prevê a classe a que um exemplo de teste pertence. Pode incluir um trecho relevante do código se ajudar a explicar.
R4: Após ter sido treinado, o classificador avalia para cada exemplo de teste e para cada classe, qual o valor do logaritmo da probabilidade atribuída pelo Kernel Density Estimator utilizado para a classe em questão e soma-a ao logaritmo da probabilidade à priori de pertencer à mesma. Depois, cada exemplo de teste é atribuido à classe que maximizou a soma anteriormente referida (ou seja, a classe a que mais provavelmente pertence).


Q5: Explique que efeito tem o parâmetro de bandwidth no seu classificador.
R5: A bandwidth influencia o valor da variância a utilizar para as distribuições normais a serem associadas aos pontos de treino. Deste modo, valores altos levam a uma superfície mais suave e difunde o impacto de cada ponto de treino, o que pode levar a cenários de underfitting. Para valores baixos verifica-se o oposto, tendo cada ponto um impacto local bastante forte.


Q6: Explique que efeito tem o parâmetro gamma no classificador SVM.
R6: O gamma determina o quão influente cada ponto de treino em relação à distancia do mesmo à fronteira de classificação. Assim, para valores de gamma altos, têm-se que um ponto distante da fronteira contribui pouco para o desenho da mesma ao passo que os pontos próximos da mesma têm um grande impacto, o que se pode refletir em situações de overfit. Para valores baixos têm-se o oposto.


Q7: Explique como determinou o melhor parâmetro de bandwidth e gamma para o seu classificador e o classificador SVM. Pode incluir um trecho relevante do código se ajudar a explicar.
R7: Para cada valor de bandwidth e gamma, treinámos os classificadores realizando cross validation utilizando stratified sampling com 5 folds sobre o conjunto de treino fornecido. No final, escolhemos os parâmetros cuja cross validation tenha devolvido o menor erro de validação médio.

Q8: Explique como obteve a melhor hipótese para cada um dos classificadores depois de optimizados os parâmetros.
R8: Treinámos uma nova instância de cada classificador com os parâmetros otimizados e os dados de treino. Depois avaliámos o desempenho dos mesmos com o conjunto de teste fornecido.


Q9: Mostre os melhores valores dos parâmetros optimizados, a estimativa do erro verdadeiro de cada uma das hipóteses que obteve (o seu classificador e os dois fornecidos pela biblioteca), os intervalos do número esperado de erros dados pelo teste normal aproximado e os valores dos testes de McNemar e discuta o que pode concluir daí.
R9: Teste normal aproximado:
- NB com KDE (bandwidth: 0.22): 56 ± 14.3342
- GaussianNB: 118 ± 20.2587
- SVM (gamma: 2.8): 50 ± 13.5786

McNemar:
- NB com KDE vs GaussianNB: 35.10
- NB com KDE vs SVM: 3.12
- GaussianNB vs SVM: 41.56

Para os valores do teste de McNemar superiores a 3.84 podemos rejeitar com 95% de confiança a hipótese de que os classificadores têm o mesmo desempenho, o que, aliado aos resultados do teste normal aproximado (O intervalo de NB com KDE interseta com o de SVM e nenhum destes se interseta com o de GaussianNB) nos permite concluir que o NB com KDE e SVM se ajustam aos dados de forma semelhante e que ambos são melhores do que o GaussianNB.


Q10: (Opcional) Mostre a estimativa do erro verdadeiro do classificador SVM optimizado (se fez a parte opcional do trabalho) e discuta se valeu a pena fazer essa optimização. Se não fez a parte opcional do trabalho deixe esta resposta em branco.
R10: Com 51 ± 13.7080 de erro e 0.00 no teste de McNemar em relação ao SVM com C fixo a 1, o SVM otimizado não apresenta melhorias que façam valer a pena o tempo acrescido de treino.

